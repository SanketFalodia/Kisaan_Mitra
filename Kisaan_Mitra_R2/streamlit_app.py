import streamlit as st
import asyncio
import os

from speech_to_text_free import transcribe_audio_local
from intent_detector import detect_intent
from multilingual_retriever import retrieve_schemes
from ollama_llm import call_mistral
from text_to_speech_free import synthesize_speech

st.set_page_config(page_title="Kisaan Mitra ЁЯМ╛", layout="centered")

st.title("ЁЯМ╛ Kisaan Mitra тАУ Voice AI Assistant")

os.makedirs("temp_audio", exist_ok=True)

uploaded_audio = st.file_uploader("ЁЯОд рдХрд┐рд╕рд╛рди рдЕрдкрдиреА рдЖрд╡рд╛рдЬрд╝ рдЕрдкрд▓реЛрдб рдХрд░реЗрдВ", type=["wav", "mp3"])

user_text_input = st.text_input("тЬНя╕П рдпрд╛ рдЕрдкрдирд╛ рдкреНрд░рд╢реНрди рд▓рд┐рдЦреЗрдВ")

if st.button("ЁЯФН рдЙрддреНрддрд░ рдкреНрд░рд╛рдкреНрдд рдХрд░реЗрдВ"):
    with st.spinner("Processing..."):
        # 1я╕ПтГг Get text
        if uploaded_audio:
            audio_path = f"temp_audio/{uploaded_audio.name}"
            with open(audio_path, "wb") as f:
                f.write(uploaded_audio.read())

            user_text = asyncio.run(transcribe_audio_local(audio_path))
        else:
            user_text = user_text_input

        if not user_text:
            st.error("тЭМ рдХреЛрдИ рдЗрдирдкреБрдЯ рдирд╣реАрдВ рдорд┐рд▓рд╛")
            st.stop()

        st.success(f"ЁЯСитАНЁЯМ╛ рдХрд┐рд╕рд╛рди рдХрд╛ рдкреНрд░рд╢реНрди: {user_text}")

        # 2я╕ПтГг Intent
        intent = detect_intent(user_text)
        st.info(f"ЁЯОп Detected Intent: {intent}")

        # 3я╕ПтГг RAG
        schemes = retrieve_schemes(user_text, intent)

        # 4я╕ПтГг LLM
        response = call_mistral(user_text, schemes)
        st.markdown("### ЁЯдЦ рдЙрддреНрддрд░")
        st.write(response)

        # 5я╕ПтГг TTS
        audio_path = asyncio.run(synthesize_speech(response))
        st.audio(audio_path)
